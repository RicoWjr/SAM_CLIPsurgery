# SAM + CLIP surgery Test

**Note**: This project was created at the end of 2022, when **SAM** had just been proposed, but the **"text"** was not used as a **guide** to segment objects with specific semantics. As descirbed in **_CLIP surgery_**, a great explainable work by HKUST, combining it with **SAM** is able to achieve understanding and segmentation of objects with only text inputs by **Text2Points**. This project aims to apply this combination into some complex scenarios in public and private datasets and test the effect.

## Related work
SAM: [https://github.com/facebookresearch/segment-anything](https://github.com/facebookresearch/segment-anything)

CLIP surgery: [https://github.com/xmed-lab/CLIP_Surgery](https://github.com/xmed-lab/CLIP_Surgery)

## Visualization

<img src="helmet.png" width="75%" />


<img src="car.png" width="75%" />
